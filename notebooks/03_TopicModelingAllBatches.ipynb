{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling\n",
    "- This notebook walks thru a topic modeling process using `data/interim/subset_first_15000.gzip` \n",
    "- At the end of the notebook, a labeled data will be returned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to parent directory\n",
    "import os\n",
    "os.chdir(os.pardir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pickle \n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "\n",
    "import warnings\n",
    "# warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper Function to process raw data by chunks \n",
    "(Functions from `data_prep` package)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jhonsen/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from src.data_prep.topic_modeling_helpers import (preprocess_text, make_corpus,extract_labels,\n",
    "                                                  find_best_crime_topic,build_lda_model, \n",
    "                                                  extract_labels)\n",
    "from src.data_prep.preprocessing_helpers import impute_nans, remove_empty_articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each chunk:\n",
    "- preprocess text file (remove empty articles, impute nans)\n",
    "- topic model it\n",
    "- find best topic modeled as \"crime\" \n",
    "    - keywords: ['black', 'police', 'violence', 'kill', 'arrest']\n",
    "- save each labeled news into `data/interim` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTs (Hyperparameters) from previous notebook (TopicModelingFirstBatch.ipynb)\n",
    "ALPHA = 'asymmetric'\n",
    "ETA = 1\n",
    "NTOPICS = 14\n",
    "\n",
    "# Helper functions\n",
    "def create_topic_model(dataset, start_row, end_row):\n",
    "\n",
    "    # Preprocess \n",
    "    papers = dataset['article'].apply(preprocess_text)\n",
    "    # Prepare topic modeling input\n",
    "    corpus, id2word, bigrams, data_lemmatized = make_corpus(papers)\n",
    "    # Build model & print the topic number with best matching keywords\n",
    "    lda_model = build_lda_model(corpus, id2word, n_topics=NTOPICS, alpha=ALPHA, eta=ETA)\n",
    "    best_topic_no = find_best_crime_topic(lda_model, n_topics=NTOPICS)\n",
    "    # label document\n",
    "    dataset['topic'] = extract_labels(lda_model, data_lemmatized, corpus, n_topics=NTOPICS)\n",
    "    crime_subset = dataset[dataset.topic==best_topic_no]\n",
    "    \n",
    "    # Save subset of crime (labeled) file\n",
    "    filename = f'labeled_crime_row{start_row}_to_row{end_row}.gzip'\n",
    "    filepath = os.path.join('data', 'interim', filename)\n",
    "    crime_subset.to_parquet(filepath, compression='gzip')\n",
    "    print(f'{filename} has ', crime_subset.shape[0], ' rows')\n",
    "    return crime_subset, best_topic_no, filename\n",
    "        \n",
    "def process_chunk(dataset, start_row, end_row):\n",
    "    return create_topic_model(impute_nans(remove_empty_articles(dataset)), start_row, end_row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing each chunk\n",
    "**BEWARE** This takes **13 hours** to run locally! \n",
    "  \n",
    "Output:  \n",
    "- `data/interim/labeled_crime_row{start_row}_to_row{end_row}.gzip`\n",
    "- `data/interim/crime_topic_index.gzip` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def start(chunksize, start_row, end_row):\n",
    "    data_directory = 'data'\n",
    "    raw_filepath = os.path.join(os.path.relpath('.'), 'data', 'raw', 'all-the-news-2-1.csv')\n",
    "\n",
    "    confirm = input(\"do you want to start? [y/n]\")\n",
    "    if (confirm == 'y') or (confirm =='Y'):\n",
    "\n",
    "        all_crime_news = pd.DataFrame()\n",
    "        crime_topic_index = pd.DataFrame()\n",
    "        for chunk in pd.read_csv(raw_filepath, header=0,\n",
    "                                 chunksize=chunksize, \n",
    "                                 encoding='utf-8',\n",
    "                                 usecols = [\"date\",\"author\",\"title\",\"publication\",\"section\",\"url\", \"article\"],\n",
    "                                 parse_dates=['date']\n",
    "                                ):\n",
    "            crime_news, best_topic_no, fname = process_chunk(chunk, start_row, end_row)\n",
    "\n",
    "            crime_topic_index = crime_topic_index.append(pd.DataFrame({'filename': fname, 'topic': best_topic_no,\n",
    "                                                                      'start_row': start_row, 'end_row': end_row},\n",
    "                                                                     columns=['filename','topic','start_row','end_row'], index=[0]), ignore_index=True)\n",
    "            all_crime_news = all_crime_news.append(crime_news, ignore_index=True)\n",
    "\n",
    "            #print(f'\\t===== Finished with first {end_row} rows ====\\n')\n",
    "            start_row += chunksize\n",
    "            end_row += chunksize\n",
    "\n",
    "        filepath = os.path.join('data', 'interim', 'crime_topic_index.gzip')\n",
    "        crime_topic_index.to_parquet(filepath, compression='gzip')\n",
    "    \n",
    "    print('complete')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "do you want to start? [y/n] y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labeled_crime_row1_to_row20000.gzip has  1720  rows\n",
      "labeled_crime_row20001_to_row40000.gzip has  2047  rows\n",
      "labeled_crime_row40001_to_row60000.gzip has  2288  rows\n",
      "labeled_crime_row60001_to_row80000.gzip has  1523  rows\n",
      "labeled_crime_row80001_to_row100000.gzip has  1733  rows\n",
      "labeled_crime_row100001_to_row120000.gzip has  1411  rows\n",
      "labeled_crime_row120001_to_row140000.gzip has  1913  rows\n",
      "labeled_crime_row140001_to_row160000.gzip has  1459  rows\n",
      "labeled_crime_row160001_to_row180000.gzip has  1245  rows\n",
      "labeled_crime_row180001_to_row200000.gzip has  899  rows\n",
      "labeled_crime_row200001_to_row220000.gzip has  2288  rows\n",
      "labeled_crime_row220001_to_row240000.gzip has  0  rows\n",
      "labeled_crime_row240001_to_row260000.gzip has  1056  rows\n",
      "labeled_crime_row260001_to_row280000.gzip has  0  rows\n",
      "labeled_crime_row280001_to_row300000.gzip has  1084  rows\n",
      "labeled_crime_row300001_to_row320000.gzip has  0  rows\n",
      "labeled_crime_row320001_to_row340000.gzip has  0  rows\n",
      "labeled_crime_row340001_to_row360000.gzip has  854  rows\n",
      "labeled_crime_row360001_to_row380000.gzip has  758  rows\n",
      "labeled_crime_row380001_to_row400000.gzip has  0  rows\n",
      "labeled_crime_row400001_to_row420000.gzip has  555  rows\n",
      "labeled_crime_row420001_to_row440000.gzip has  572  rows\n",
      "labeled_crime_row440001_to_row460000.gzip has  0  rows\n",
      "labeled_crime_row460001_to_row480000.gzip has  0  rows\n",
      "labeled_crime_row480001_to_row500000.gzip has  794  rows\n",
      "labeled_crime_row500001_to_row520000.gzip has  2250  rows\n",
      "labeled_crime_row520001_to_row540000.gzip has  0  rows\n",
      "labeled_crime_row540001_to_row560000.gzip has  531  rows\n",
      "labeled_crime_row560001_to_row580000.gzip has  1411  rows\n",
      "labeled_crime_row580001_to_row600000.gzip has  1404  rows\n",
      "labeled_crime_row600001_to_row620000.gzip has  1684  rows\n",
      "labeled_crime_row620001_to_row640000.gzip has  1250  rows\n",
      "labeled_crime_row640001_to_row660000.gzip has  1374  rows\n",
      "labeled_crime_row660001_to_row680000.gzip has  1444  rows\n",
      "labeled_crime_row680001_to_row700000.gzip has  1199  rows\n",
      "labeled_crime_row700001_to_row720000.gzip has  1344  rows\n",
      "labeled_crime_row720001_to_row740000.gzip has  1099  rows\n",
      "labeled_crime_row740001_to_row760000.gzip has  1096  rows\n",
      "labeled_crime_row760001_to_row780000.gzip has  1260  rows\n",
      "labeled_crime_row780001_to_row800000.gzip has  1174  rows\n",
      "labeled_crime_row800001_to_row820000.gzip has  1340  rows\n",
      "labeled_crime_row820001_to_row840000.gzip has  2092  rows\n",
      "labeled_crime_row840001_to_row860000.gzip has  1448  rows\n",
      "labeled_crime_row860001_to_row880000.gzip has  1628  rows\n",
      "labeled_crime_row880001_to_row900000.gzip has  1113  rows\n",
      "labeled_crime_row900001_to_row920000.gzip has  1011  rows\n",
      "labeled_crime_row920001_to_row940000.gzip has  730  rows\n",
      "labeled_crime_row940001_to_row960000.gzip has  1347  rows\n",
      "labeled_crime_row960001_to_row980000.gzip has  1399  rows\n",
      "labeled_crime_row980001_to_row1000000.gzip has  1713  rows\n",
      "labeled_crime_row1000001_to_row1020000.gzip has  1193  rows\n",
      "labeled_crime_row1020001_to_row1040000.gzip has  1108  rows\n",
      "labeled_crime_row1040001_to_row1060000.gzip has  995  rows\n",
      "labeled_crime_row1060001_to_row1080000.gzip has  1385  rows\n",
      "labeled_crime_row1080001_to_row1100000.gzip has  0  rows\n",
      "labeled_crime_row1100001_to_row1120000.gzip has  0  rows\n",
      "labeled_crime_row1120001_to_row1140000.gzip has  0  rows\n",
      "labeled_crime_row1140001_to_row1160000.gzip has  0  rows\n",
      "labeled_crime_row1160001_to_row1180000.gzip has  1094  rows\n",
      "labeled_crime_row1180001_to_row1200000.gzip has  1500  rows\n",
      "labeled_crime_row1200001_to_row1220000.gzip has  1125  rows\n",
      "labeled_crime_row1220001_to_row1240000.gzip has  893  rows\n",
      "labeled_crime_row1240001_to_row1260000.gzip has  1144  rows\n",
      "labeled_crime_row1260001_to_row1280000.gzip has  1202  rows\n",
      "labeled_crime_row1280001_to_row1300000.gzip has  1230  rows\n",
      "labeled_crime_row1300001_to_row1320000.gzip has  1334  rows\n",
      "labeled_crime_row1320001_to_row1340000.gzip has  1574  rows\n",
      "labeled_crime_row1340001_to_row1360000.gzip has  1224  rows\n",
      "labeled_crime_row1360001_to_row1380000.gzip has  0  rows\n",
      "labeled_crime_row1380001_to_row1400000.gzip has  936  rows\n",
      "labeled_crime_row1400001_to_row1420000.gzip has  1082  rows\n",
      "labeled_crime_row1420001_to_row1440000.gzip has  1254  rows\n",
      "labeled_crime_row1440001_to_row1460000.gzip has  590  rows\n",
      "labeled_crime_row1460001_to_row1480000.gzip has  0  rows\n",
      "labeled_crime_row1480001_to_row1500000.gzip has  0  rows\n",
      "labeled_crime_row1500001_to_row1520000.gzip has  1147  rows\n",
      "labeled_crime_row1520001_to_row1540000.gzip has  785  rows\n",
      "labeled_crime_row1540001_to_row1560000.gzip has  0  rows\n",
      "labeled_crime_row1560001_to_row1580000.gzip has  1385  rows\n",
      "labeled_crime_row1580001_to_row1600000.gzip has  1269  rows\n",
      "labeled_crime_row1600001_to_row1620000.gzip has  1084  rows\n",
      "labeled_crime_row1620001_to_row1640000.gzip has  0  rows\n",
      "labeled_crime_row1640001_to_row1660000.gzip has  0  rows\n",
      "labeled_crime_row1660001_to_row1680000.gzip has  3354  rows\n",
      "labeled_crime_row1680001_to_row1700000.gzip has  1058  rows\n",
      "labeled_crime_row1700001_to_row1720000.gzip has  783  rows\n",
      "labeled_crime_row1720001_to_row1740000.gzip has  0  rows\n",
      "labeled_crime_row1740001_to_row1760000.gzip has  884  rows\n",
      "labeled_crime_row1760001_to_row1780000.gzip has  1079  rows\n",
      "labeled_crime_row1780001_to_row1800000.gzip has  630  rows\n",
      "labeled_crime_row1800001_to_row1820000.gzip has  0  rows\n",
      "labeled_crime_row1820001_to_row1840000.gzip has  1616  rows\n",
      "labeled_crime_row1840001_to_row1860000.gzip has  1012  rows\n",
      "labeled_crime_row1860001_to_row1880000.gzip has  1180  rows\n",
      "labeled_crime_row1880001_to_row1900000.gzip has  0  rows\n",
      "labeled_crime_row1900001_to_row1920000.gzip has  1661  rows\n",
      "labeled_crime_row1920001_to_row1940000.gzip has  1893  rows\n",
      "labeled_crime_row1940001_to_row1960000.gzip has  1445  rows\n",
      "labeled_crime_row1960001_to_row1980000.gzip has  1489  rows\n",
      "labeled_crime_row1980001_to_row2000000.gzip has  1486  rows\n",
      "labeled_crime_row2000001_to_row2020000.gzip has  1574  rows\n",
      "labeled_crime_row2020001_to_row2040000.gzip has  1285  rows\n",
      "labeled_crime_row2040001_to_row2060000.gzip has  1627  rows\n",
      "labeled_crime_row2060001_to_row2080000.gzip has  1594  rows\n",
      "labeled_crime_row2080001_to_row2100000.gzip has  1603  rows\n",
      "labeled_crime_row2100001_to_row2120000.gzip has  1483  rows\n",
      "labeled_crime_row2120001_to_row2140000.gzip has  2329  rows\n",
      "labeled_crime_row2140001_to_row2160000.gzip has  1102  rows\n",
      "labeled_crime_row2160001_to_row2180000.gzip has  1129  rows\n",
      "labeled_crime_row2180001_to_row2200000.gzip has  825  rows\n",
      "labeled_crime_row2200001_to_row2220000.gzip has  1594  rows\n",
      "labeled_crime_row2220001_to_row2240000.gzip has  506  rows\n",
      "labeled_crime_row2240001_to_row2260000.gzip has  794  rows\n",
      "labeled_crime_row2260001_to_row2280000.gzip has  1100  rows\n",
      "labeled_crime_row2280001_to_row2300000.gzip has  1423  rows\n",
      "labeled_crime_row2300001_to_row2320000.gzip has  574  rows\n",
      "labeled_crime_row2320001_to_row2340000.gzip has  1153  rows\n",
      "labeled_crime_row2340001_to_row2360000.gzip has  0  rows\n",
      "labeled_crime_row2360001_to_row2380000.gzip has  1235  rows\n",
      "labeled_crime_row2380001_to_row2400000.gzip has  1958  rows\n",
      "labeled_crime_row2400001_to_row2420000.gzip has  1231  rows\n",
      "labeled_crime_row2420001_to_row2440000.gzip has  1240  rows\n",
      "labeled_crime_row2440001_to_row2460000.gzip has  1617  rows\n",
      "labeled_crime_row2460001_to_row2480000.gzip has  899  rows\n",
      "labeled_crime_row2480001_to_row2500000.gzip has  1962  rows\n",
      "labeled_crime_row2500001_to_row2520000.gzip has  878  rows\n",
      "labeled_crime_row2520001_to_row2540000.gzip has  1185  rows\n",
      "labeled_crime_row2540001_to_row2560000.gzip has  930  rows\n",
      "labeled_crime_row2560001_to_row2580000.gzip has  0  rows\n",
      "labeled_crime_row2580001_to_row2600000.gzip has  0  rows\n",
      "labeled_crime_row2600001_to_row2620000.gzip has  583  rows\n",
      "labeled_crime_row2620001_to_row2640000.gzip has  652  rows\n",
      "labeled_crime_row2640001_to_row2660000.gzip has  0  rows\n",
      "labeled_crime_row2660001_to_row2680000.gzip has  0  rows\n",
      "labeled_crime_row2680001_to_row2700000.gzip has  0  rows\n",
      "complete\n"
     ]
    }
   ],
   "source": [
    "###### File chunk settings\n",
    "start_row = 1\n",
    "chunksize = 20000  # This is equivalent to <25 mb parquet file\n",
    "end_row = chunksize \n",
    "\n",
    "######  Un-comment below to start! ########\n",
    "start(chunksize, start_row, end_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
